{
  "metadata": {
    "name": "safety_analysis.ipynb",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Data Source\n\nThe safety dataset is from [IRS SCHOOL SAFETY AND THE EDUCATIONAL CLIMATE](https://www.p12.nysed.gov/irs/school_safety/school_safety_data_reporting.htmll).\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Data Analysis on Safety Data"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val safetyIssueColumns \u003d Seq(\n  \"Homocide\",\n  \"Sexual_Offense\",\n  \"Assault\",\n  \"Weapons_Possession\",\n  \"Dignity Act-Excluding_Cyberbullying\",\n  \"Dignity Act-Cyberbullying\",\n  \"Bomb_Threat\",\n  \"False_Alarm\",\n  \"Drugs\",\n  \"Alcohol\"\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nyccounties \u003d \"(\u0027QUEENS\u0027,  \u0027BRONX\u0027, \u0027RICHMOND\u0027, \u0027NEW YORK\u0027, \u0027KINGS\u0027)\""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Per District"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## In NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nimport org.apache.spark.sql.DataFrame\n\nvar totalNYCCountyDF: DataFrame \u003d spark.emptyDataFrame\n\nvar count: Long \u003d 0\n\nfor (year \u003c- 2018 to 2023) {\n    \n    val filePath \u003d s\"project/cleaned_data/safety$year.csv\"\n    val safetydf \u003d spark.read\n        .option(\"multiLine\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"escape\", \"\\\"\")\n        .option(\"header\", true)\n        .csv(filePath)\n\n    safetydf.createOrReplaceTempView(s\"safety$year\")\n    \n    count \u003d safetydf.count()\n\n    var countydf \u003d spark.sql(s\"\"\"\n        select `County`, ${safetyIssueColumns.map(col \u003d\u003e s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n        from safety$year\n        where `County` in ${nyccounties}\n        group by `County`\n    \"\"\").withColumn(\"Year\", lit(year))\n    \n    val columns \u003d Seq(\"Year\") ++ countydf.columns.slice(0, 11)\n    var countydfNew \u003d countydf.select(columns.map(countydf.col): _*)\n\n    totalNYCCountyDF \u003d if (totalNYCCountyDF.isEmpty) countydfNew else totalNYCCountyDF.union(countydfNew)\n}\n\nz.show(totalNYCCountyDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val avgSafetyIssueColumns \u003d totalNYCCountyDF.columns.filter(col \u003d\u003e col !\u003d \"Year\" \u0026\u0026 col !\u003d \"County\")"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "totalNYCCountyDF.createOrReplaceTempView(\"totalNYCCounty\")\n\nval NYCcountyYoYDF \u003d spark.sql(s\"\"\"\n  select\n    cur.County,\n    cur.Year,\n    ${avgSafetyIssueColumns.map{col \u003d\u003e\n        val name \u003d col.replace(\" \", \"_\").replace(\"-\", \"_\")\n        s\"round((cur.`$col` - prev.`$col`) / prev.`$col` * 100, 2) AS `${name}_YoY (%)`\"\n    }.mkString(\",\\n    \")}\n  from\n    totalNYCCounty cur\n  join\n    totalNYCCounty prev\n  on\n    cur.Year \u003d prev.Year + 1\n    and cur.County \u003d prev.County\n\"\"\")\n\nz.show(NYCcountyYoYDF)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Outside of NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var totalOutCountyDF: DataFrame \u003d spark.emptyDataFrame\n\nfor (year \u003c- 2018 to 2023) {\n    var countydf \u003d spark.sql(s\"\"\"\n        select `County`, ${safetyIssueColumns.map(col \u003d\u003e s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n        from safety$year\n        where `County` not in ${nyccounties}\n        group by `County`\n    \"\"\").withColumn(\"Year\", lit(year))\n    \n    val columns \u003d Seq(\"Year\") ++ countydf.columns.slice(0, 11)\n    var countydfNew \u003d countydf.select(columns.map(countydf.col): _*)\n\n    totalOutCountyDF \u003d if (totalOutCountyDF.isEmpty) countydfNew else totalOutCountyDF.union(countydfNew)\n}\n\nz.show(totalOutCountyDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val distinctCountiesDF \u003d totalOutCountyDF.select(\"County\").distinct()\ndistinctCountiesDF.show(Int.MaxValue, truncate \u003d false)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// totalOutCountyDF.createOrReplaceTempView(\"totalOutCounty\")\n\nval topOutCountyDF \u003d totalOutCountyDF.withColumn(\n  \"Sum_Safety_Issues\",\n  avgSafetyIssueColumns.map(colName \u003d\u003e col(colName)).reduce(_ + _)\n)\n\nval avgSafetyIssuesDF \u003d topOutCountyDF\n  .groupBy(\"County\")\n  .agg(avg(\"Sum_Safety_Issues\").as(\"Avg_Sum_Safety_Issues\"))\n  .orderBy(desc(\"Avg_Sum_Safety_Issues\"))\n\nz.show(avgSafetyIssuesDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "avgSafetyIssuesDF.createOrReplaceTempView(\"avgSafetyIssues\")\n\nval temp2 \u003d spark.sql(\"\"\" \n    select *\n    from avgSafetyIssues\n    where County \u003d \"NEW YORK\"\n\"\"\")\n\nz.show(temp2)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "totalOutCountyDF.createOrReplaceTempView(\"totalOutCounty\")\n\nval outCountyYoYDF \u003d spark.sql(s\"\"\"\n  select\n    cur.County,\n    cur.Year,\n    ${avgSafetyIssueColumns.map{col \u003d\u003e\n        val name \u003d col.replace(\" \", \"_\").replace(\"-\", \"_\")\n        s\"round((cur.`$col` - prev.`$col`) / prev.`$col` * 100, 2) AS `${name}_YoY (%)`\"\n    }.mkString(\",\\n    \")}\n  from\n    totalOutCounty cur\n  join\n    totalOutCounty prev\n  on\n    cur.Year \u003d prev.Year + 1\n    and cur.County \u003d prev.County\n\"\"\")\n\nz.show(outCountyYoYDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Per School"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// concat all the cleaned datasets views from 2018 to 2023 into one\nval allDF \u003d spark.sql(\"\"\"\n  select * , 2018 as Year from safety2018\n  union all\n  select * , 2019 as Year from safety2019\n  union all\n  select * , 2020 as Year from safety2020\n  union all\n  select * , 2021 as Year from safety2021\n  union all\n  select * , 2022 as Year from safety2022\n  union all\n  select * , 2023 as Year from safety2023\n\"\"\")\n\nallDF.createOrReplaceTempView(\"all\")\n\nz.show(allDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## In NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val NYCschoolDF \u003d spark.sql(s\"\"\"\n    select BEDS_Code, County, ${safetyIssueColumns.map(col \u003d\u003e s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n    from all\n    where County in ${nyccounties}\n    group by BEDS_Code, County\n\"\"\").withColumn(\"Sum_Avg_Safety_Issues\", avgSafetyIssueColumns.map(col).reduce(_ + _))\n\nz.show(NYCschoolDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "NYCschoolDF.createOrReplaceTempView(\"NYCschool\")\n\nval topNYCSchoolDF \u003d spark.sql(\"\"\"\n    select *\n    from NYCschool\n    order by Sum_Avg_Safety_Issues desc\n    limit 10\n\"\"\")\n\nz.show(topNYCSchoolDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Outside of NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val outSchoolDF \u003d spark.sql(s\"\"\"\n    select BEDS_Code, County, ${safetyIssueColumns.map(col \u003d\u003e s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n    from all\n    where County not in ${nyccounties}\n    group by BEDS_Code, County\n\"\"\").withColumn(\"Sum_Avg_Safety_Issues\", avgSafetyIssueColumns.map(col).reduce(_ + _))\n\nz.show(outSchoolDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "outSchoolDF.createOrReplaceTempView(\"outSchool\")\n\nval topOutSchoolDF \u003d spark.sql(\"\"\"\n    select *\n    from outSchool\n    order by Sum_Avg_Safety_Issues desc\n    limit 10\n\"\"\")\n\nz.show(topOutSchoolDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Per Safety Issue"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## In NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var avgNYCSafetyIssueDF: DataFrame \u003d spark.emptyDataFrame\n\nfor (year \u003c- 2018 to 2023) {\n    \n    // sum the number of each violations / number of schools\n    var avg \u003d spark.sql(s\"\"\"\n        select ${safetyIssueColumns.map(col \u003d\u003e s\"sum(`$col`)/$count as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n        from safety${year}\n        where County in $nyccounties\n    \"\"\").withColumn(\"Year\", lit(year))\n    \n    val columns \u003d Seq(\"Year\") ++ avg.columns.slice(0, 10)\n    var avgNew \u003d avg.select(columns.map(avg.col): _*)\n    \n    avgNYCSafetyIssueDF \u003d if (avgNYCSafetyIssueDF.isEmpty) avgNew else avgNYCSafetyIssueDF.union(avgNew)\n}\n\nz.show(avgNYCSafetyIssueDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "avgNYCSafetyIssueDF.createOrReplaceTempView(\"avg_nyc_safety_issues\")\n\nval maxNYCSafetyIssuesDF \u003d spark.sql(s\"\"\"\n    select *,\n            case\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Homocide` then \u0027Avg_Homocide\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Sexual_Offense` then \u0027Avg_Sexual_Offense\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Assault` then \u0027Avg_Assault\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Weapons_Possession` then \u0027Avg_Weapons_Possession\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Dignity_Act_Excluding_Cyberbullying` then \u0027Avg_Dignity_Act_Excluding_Cyberbullying\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Dignity_Act_Cyberbullying` then \u0027Avg_Dignity_Act_Cyberbullying\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Bomb_Threat` then \u0027Avg_Bomb_Threat\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_False_Alarm` then \u0027Avg_False_Alarm\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Drugs` then \u0027Avg_Drugs\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Alcohol` then \u0027Avg_Alcohol\u0027\n                else \u0027Unknown\u0027\n            end as Max_Safety_Issue\n    from avg_nyc_safety_issues\n\"\"\")\n\nz.show(maxNYCSafetyIssuesDF)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Outside of NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var avgOutSafetyIssueDF: DataFrame \u003d spark.emptyDataFrame\n\nfor (year \u003c- 2018 to 2023) {\n    \n    // sum the number of each violations / number of schools\n    var avg \u003d spark.sql(s\"\"\"\n        select ${safetyIssueColumns.map(col \u003d\u003e s\"sum(`$col`)/$count as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n        from safety${year}\n        where County not in $nyccounties\n    \"\"\").withColumn(\"Year\", lit(year))\n    \n    val columns \u003d Seq(\"Year\") ++ avg.columns.slice(0, 10)\n    var avgNew \u003d avg.select(columns.map(avg.col): _*)\n    \n    avgOutSafetyIssueDF \u003d if (avgOutSafetyIssueDF.isEmpty) avgNew else avgOutSafetyIssueDF.union(avgNew)\n}\n\nz.show(avgOutSafetyIssueDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "avgOutSafetyIssueDF.createOrReplaceTempView(\"avg_out_safety_issues\")\n\nval maxOutSafetyIssuesDF \u003d spark.sql(s\"\"\"\n    select *,\n            case\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Homocide` then \u0027Avg_Homocide\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Sexual_Offense` then \u0027Avg_Sexual_Offense\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Assault` then \u0027Avg_Assault\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Weapons_Possession` then \u0027Avg_Weapons_Possession\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Dignity_Act_Excluding_Cyberbullying` then \u0027Avg_Dignity_Act_Excluding_Cyberbullying\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Dignity_Act_Cyberbullying` then \u0027Avg_Dignity_Act_Cyberbullying\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Bomb_Threat` then \u0027Avg_Bomb_Threat\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_False_Alarm` then \u0027Avg_False_Alarm\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Drugs` then \u0027Avg_Drugs\u0027\n                when greatest(${avgSafetyIssueColumns.map(col \u003d\u003e s\"`${col}`\").mkString(\", \")}) \u003d `Avg_Alcohol` then \u0027Avg_Alcohol\u0027\n                else \u0027Unknown\u0027\n            end as Max_Safety_Issue\n    from avg_out_safety_issues\n\"\"\")\n\nz.show(maxOutSafetyIssuesDF)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Save data"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Per District\ntotalNYCCountyDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/TotalNYCCounty.csv\")\nNYCcountyYoYDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/NYCcountyYoY.csv\")\ntotalOutCountyDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/TotalOutCounty.csv\")\noutCountyYoYDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/OutCountyYoY.csv\")\n\n// Per School\ntopNYCSchoolDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/topNYCSchool.csv\")\ntopOutSchoolDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/topOutSchool.csv\")\n\n// Per Safety Issue\nmaxNYCSafetyIssuesDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/MaxNYCSafetyIssues.csv\")\nmaxOutSafetyIssuesDF.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"project/analyzed_data/MaxOutSafetyIssues.csv\")"
    }
  ]
}