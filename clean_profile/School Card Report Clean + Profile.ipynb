{
  "metadata": {
    "name": "NRC \u0026 Grad Rate Data Clean + Profile",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# SCR Data Profile\n\u003e Kamiku Xue(yx3494@nyu.edu)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// define the project root\nimport org.apache.spark.sql.DataFrame\nval root_folder \u003d \"/user/yx3494_nyu_edu/scr_data/\""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1 BOCES and Need-to-Resource Capacity Categories(N/RC)\n\nThe need-to-resource capacity (N/RC) index, a measure of a district’s ability to meet the needs of its students with local\nresources, is the ratio of the estimated poverty percentage1 (expressed in standard score form) to the Combined Wealth\nRatio2 (expressed in standard score form). A district with both estimated poverty and Combined Wealth Ratio equal to\nthe State average would have a N/RC index of 1.0. N/RC categories are determined from this index using the definitions\nin the table below."
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// First see the data schema\nfor (i \u003c- 2018 to 2023){\n    var df \u003d spark.read.option(\"header\", \"true\")\n        .option(\"multiLine\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"escape\", \"\\\"\")\n        .csv(root_folder + i + \"/BOCES_NRC.csv\")\n\n        println(\"Year \" + i)\n        println(\"Total Columns \" + df.columns.length)\n        \n        // see data structure\n        df.printSchema\n        // peek some data\n        z.show(df.limit(3))\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\nWe will use the following columns:\n\n- `ENTITY_CD `: Unique identifier for the entity for foreign key\n- `SCHOOL_NAME`: The name of the school\n- `YEAR`: School Year (2021 for 2020-21, 2022 for 2021-22, 2023 for 2022-23)\n- `DISTRICT_NAME`: The name of the district\n- `COUNTY_NAME`: The name of the county\n- `NEEDS_INDEX`: N/RC index\n\nNow profile the each column"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// loop from 2018 to 2023 profile the NRC\nfor (i \u003c- 2018 to 2023){\n    var df \u003d spark.read.option(\"header\", \"true\")\n        .option(\"multiLine\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"escape\", \"\\\"\")\n        .csv(root_folder + i + \"/BOCES_NRC.csv\")\n\n        println(\"\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Year \" + i + \" \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\")\n        println(\"Total entities \" + df.count)\n\n        // profile the YEAR\n        println(\"YEAR Profile\")\n        z.show(df.groupBy(\"YEAR\").count().orderBy(\"YEAR\")) // -\u003e 3, this explains some entities occur more than once, because they are in different years\n\n        // profile the ENTITY_CD\n        println(\"ENTITY_CD Profile, distinct entities: \" + df.select(\"ENTITY_CD\").distinct.count)\n        println(\"empty, null values: \" + df.filter(\"ENTITY_CD is null or ENTITY_CD \u003d \u0027\u0027\").count)\n        val groups_ids \u003d df.groupBy(\"ENTITY_CD\").count()\n        z.show(groups_ids.select(\"count\").describe()) // max: 3, min: 2, avg: 2.99 -\u003e most of the entities occur 3 times\n\n        // profile the SCHOOL_NAME\n        println(\"SCHOOL_NAME Profile, distinct schools:\" + df.select(\"SCHOOL_NAME\").distinct.count)\n        val groups_schools \u003d df.groupBy(\"SCHOOL_NAME\").count()\n        z.show(groups_schools.describe()) // some values occur 12 times, no empty names\n\n        // need to bind the SCHOOL_NAME with ENTITY_CD to check if the same school has different entity code\n        println(\"CHOOL_NAME + ENTITY_CD Profile, Distribution of entities\")\n        val groups_schools_entity \u003d df.groupBy(\"ENTITY_CD\", \"SCHOOL_NAME\").count().select(\"count\")\n        z.show(groups_schools_entity.describe()) // max: 3, min: 2, avg: 2.99 -\u003e match the entity_cd\n\n        // profile the DISTRICT_NAME\n        println(\"DISTRICT_NAME Profile, unique districts: \" + df.select(\"DISTRICT_NAME\").distinct.count)\n        \n        //group by YEAR for the NEEDS_INDEX\n        val groups_districts \u003d df.groupBy(\"DISTRICT_NAME\").count()\n        z.show(groups_districts.describe()) //DISTRICT max occur 800, min 5 times\n\n        // profile the NEEDS_INDEX\n        println(\"NEEDS_INDEX Profile\")\n        z.show(df.describe(\"NEEDS_INDEX\")) // max:7, min: 1, avg: 3.55, stddev: 2.09\n        \n        //differset school year NEEDS_INDEX distribution\n        println(\"NEEDS_INDEX Profile in different years\")\n        z.show(df\n        .groupBy(\"YEAR\")\n        .agg(\n            sum(\"NEEDS_INDEX\"),\n            avg(\"NEEDS_INDEX\"), \n            min(\"NEEDS_INDEX\"), \n            max(\"NEEDS_INDEX\"), \n            stddev(\"NEEDS_INDEX\")\n        )\n        .orderBy(\"YEAR\"))\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n### N/RC Clean Step\n\nWe will do the following steps to clean the data"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n//  Define UDFs for the Index Descrption\nval getNeedIndex \u003d (index: Int) \u003d\u003e {\n    index match {\n    case 1 \u003d\u003e \"High N/RC: New York City\"\n    case 2 \u003d\u003e \"High N/RC: Large City Districts \"\n    case 3 \u003d\u003e \"High N/RC: Urban-Suburban Districts\"\n    case 4 \u003d\u003e \"High N/RC: Rural Districts\"\n    case 5 \u003d\u003e \"Average N/RC Districts\"\n    case 6 \u003d\u003e \"Low N/RC Districts\"\n    case 7 \u003d\u003e \"Charter Schools\"\n    case _ \u003d\u003e \"Other\"\n    }\n}\n\nspark.udf.register(\"nrcStr\", getNeedIndex)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// create a dataframe to store the data for all years\nvar nrcDF : DataFrame \u003d null\nfor (i \u003c- 2018 to 2023){\n    var df \u003d spark.read.option(\"header\", \"true\")\n        .option(\"multiLine\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"escape\", \"\\\"\")\n        .csv(root_folder + i + \"/BOCES_NRC.csv\")\n        // filder other year\u0027s data\n        .filter(\"YEAR \u003d \" + i)\n        // drop null values in SCHOOL_NAME\n        .filter(\"SCHOOL_NAME is not null and SCHOOL_NAME !\u003d \u0027\u0027\")\n        // in DISTRICT_NAME, if null, replace with \u0027UNAVAILABLE\u0027\n        .withColumn(\"DISTRICT_NAME\", when(col(\"DISTRICT_NAME\").isNull, \"UNAVAILABLE\").otherwise(col(\"DISTRICT_NAME\")))\n        .withColumn(\"NEEDS_DESCRIPTION\", expr(\"nrcStr(NEEDS_INDEX)\"))\n        .select(\"ENTITY_CD\", \"SCHOOL_NAME\", \"YEAR\", \"NEEDS_INDEX\", \"NEEDS_DESCRIPTION\", \"COUNTY_NAME\", \"DISTRICT_NAME\")\n    if (nrcDF \u003d\u003d null){\n        nrcDF \u003d df\n    } else {\n        nrcDF \u003d nrcDF.union(df)\n    }\n}\n\nnrcDF.printSchema\nval nrcCount \u003d nrcDF.count\nz.show(nrcDF.groupBy(\"Year\").count())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### NR/C Analysis (Post Profile)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(nrcDF.groupBy(\"COUNTY_NAME\").count().orderBy(\"COUNTY_NAME\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// see all level distribution\nfor(i \u003c- 1 to 7){\n    println(getNeedIndex(i))\n    \n    z.show(nrcDF\n    .filter(s\"NEEDS_INDEX \u003d ${i}\")\n    .groupBy(\"COUNTY_NAME\")\n    .count()\n    .orderBy(desc(\"count\"))\n    )\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Output Cleaned Data"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Final NR/C Dataframe (Total: \" + nrcDF.count + \") \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\")\nval nrc_cleaned_Df \u003d nrcDF \n// only select the columns we need\n.drop(\"COUNTY_NAME\", \"DISTRICT_NAME\")\n// rename the columns\n.withColumnRenamed(\"ENTITY_CD\", \"School_BEDS_Code\")\n.withColumnRenamed(\"SCHOOL_NAME\", \"School_Name\")\n.withColumnRenamed(\"YEAR\", \"Year\")\n.withColumnRenamed(\"NEEDS_INDEX\", \"N/RC_Index\")\n.withColumnRenamed(\"NEEDS_DESCRIPTION\", \"N/RC_Index_Description\")\nz.show(nrc_cleaned_Df.limit(10))\nnrc_cleaned_Df.write.mode(\"overwrite\").parquet(root_folder + \"nrc_cleaned.parquet\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2 Graudation Rate(High School Only)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// see the structure and data\nfor (i \u003c- 2018 to 2023){\n    var df \u003d spark.read.option(\"header\", \"true\")\n        .option(\"multiLine\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"escape\", \"\\\"\")\n        .csv(root_folder + i + \"/Graduation_Rate.csv\")\n    println(\"\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Year \" + i + \" \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\")\n    // show the schema\n    println(\"Columns: \" + df.columns.length)\n    df.printSchema\n    z.show(df.limit(5))\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Clean Data\n\n- Merget the 2018 -2023 data\n- Rename the coloums"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// define the root df\nvar gradDF : DataFrame \u003d null\nfor (i \u003c- 2018 to 2023){\n    var df \u003d spark.read.option(\"header\", \"true\")\n        .option(\"multiLine\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"escape\", \"\\\"\")\n        .csv(root_folder + i + \"/Graduation_Rate.csv\")\n        // filter the current year data\n        .filter(\"YEAR \u003d \" + i)\n        // select the columns we need\n        .select(\"YEAR\", \"ENTITY_CD\", \"ENTITY_NAME\", \"SUBGROUP_NAME\", \"COHORT\", \"GRAD_RATE\")\n        \n    if (gradDF \u003d\u003d null){\n        gradDF \u003d df\n    } else {\n        gradDF \u003d gradDF.union(df)\n    }\n}\n\nprintln(\"\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d Final Graduation Rate Dataframe (Total: \" + gradDF.count + \") \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\")\ngradDF.printSchema"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n### Profile"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//  by year\nz.show(gradDF.groupBy(\"Year\").count().orderBy(\"Year\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//  by subgroup types\nz.show(gradDF.groupBy(\"SUBGROUP_NAME\").count().orderBy(\"SUBGROUP_NAME\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// merge English Language Learner\ngradDF \u003d gradDF.withColumn(\n    \"SUBGROUP_NAME\",\n    when(col(\"SUBGROUP_NAME\") \u003d\u003d\u003d \"English Language Learner\", \"English Language Learners\")\n      .otherwise(col(\"SUBGROUP_NAME\"))\n)\nz.show(gradDF.groupBy(\"SUBGROUP_NAME\").count().orderBy(\"SUBGROUP_NAME\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// by cohort types\nz.show(gradDF.groupBy(\"COHORT\").count())"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval _4_year_rate \u003d gradDF.filter($\"SUBGROUP_NAME\" \u003d\u003d\u003d \"All Students\" \u0026\u0026 $\"GRAD_RATE\" \u003d!\u003d \"s\" \u0026\u0026 $\"COHORT\" \u003d\u003d\u003d \"4-Year\").count\nval _5_year_rate \u003d gradDF.filter($\"SUBGROUP_NAME\" \u003d\u003d\u003d \"All Students\" \u0026\u0026 $\"GRAD_RATE\" \u003d!\u003d \"s\" \u0026\u0026 $\"COHORT\" \u003d\u003d\u003d \"5-Year\").count\nval _6_year_rate \u003d gradDF.filter($\"SUBGROUP_NAME\" \u003d\u003d\u003d \"All Students\" \u0026\u0026 $\"GRAD_RATE\" \u003d!\u003d \"s\" \u0026\u0026 $\"COHORT\" \u003d\u003d\u003d \"6-Year\").count\n\n// invalid records\nval invalid_rate \u003d gradDF.filter($\"SUBGROUP_NAME\" \u003d\u003d\u003d \"All Students\" \u0026\u0026 $\"GRAD_RATE\" \u003d\u003d\u003d \"s\" \u0026\u0026 $\"COHORT\" \u003d\u003d\u003d \"Combined\").count\n// valid records\nval valid_Rate \u003d gradDF.filter($\"SUBGROUP_NAME\" \u003d\u003d\u003d \"All Students\" \u0026\u0026 $\"GRAD_RATE\" \u003d!\u003d \"s\" \u0026\u0026 $\"COHORT\" \u003d\u003d\u003d \"Combined\").count"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "This mean for the invalid reocrd, we can get the rate form the average value 4 year, 5 year and 6 year value."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Clean and output"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// get all entities combine grad rate\nval entityGradRate \u003d gradDF\n.filter(\"SUBGROUP_NAME \u003d \u0027All Students\u0027 AND COHORT !\u003d \u0027Combined\u0027 AND GRAD_RATE !\u003d \u0027s\u0027\")\n.groupBy(\"ENTITY_CD\", \"YEAR\")\n// get the avaerage grad rate\n.agg(avg(\"GRAD_RATE\").alias(\"Graduation_Rate\"))\n// rename the column\n.withColumnRenamed(\"ENTITY_CD\", \"School_BEDS_Code\")\n.withColumnRenamed(\"YEAR\", \"Year\")\n\nschoolYearGradRate.printSchema\n\n// show the distribution,invse the order\nz.show(schoolYearGradRate.orderBy(desc(\"Graduation_Rate\")).limit(10))\nz.show(schoolYearGradRate.groupBy(\"Year\").count())\nz.show(schoolYearGradRate.describe())\n\n// save the dataframe\nschoolYearGradRate.write.mode(\"overwrite\").parquet(root_folder + \"grad_rate_cleaned.parquet\")"
    }
  ]
}