{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Source\n",
        "\n",
        "The safety dataset is from [IRS SCHOOL SAFETY AND THE EDUCATIONAL CLIMATE](https://www.p12.nysed.gov/irs/school_safety/school_safety_data_reporting.htmll).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analysis on Safety Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "val safetyIssueColumns = Seq(\n",
        "  \"Homocide\",\n",
        "  \"Sexual_Offense\",\n",
        "  \"Assault\",\n",
        "  \"Weapons_Possession\",\n",
        "  \"Dignity Act-Excluding_Cyberbullying\",\n",
        "  \"Dignity Act-Cyberbullying\",\n",
        "  \"Bomb_Threat\",\n",
        "  \"False_Alarm\",\n",
        "  \"Drugs\",\n",
        "  \"Alcohol\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "val nyccounties = \"('QUEENS', 'MANHATTAN', 'BROOKLYN', 'BRONX', 'RICHMOND')\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Per District"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In NYC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "\n",
        "import org.apache.spark.sql.DataFrame\n",
        "\n",
        "var totalNYCCountyDF: DataFrame = spark.emptyDataFrame\n",
        "\n",
        "for (year <- 2018 to 2023) {\n",
        "    \n",
        "    val filePath = s\"project/cleaned_data/safety$year.csv\"\n",
        "    val safetydf = spark.read\n",
        "        .option(\"multiLine\", \"true\")\n",
        "        .option(\"inferSchema\", \"true\")\n",
        "        .option(\"escape\", \"\\\"\")\n",
        "        .option(\"header\", true)\n",
        "        .csv(filePath)\n",
        "\n",
        "    safetydf.createOrReplaceTempView(s\"safety$year\")\n",
        "\n",
        "    var countydf = spark.sql(s\"\"\"\n",
        "        select `County`, ${safetyIssueColumns.map(col => s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n",
        "        from safety$year\n",
        "        where `County` in ${nyccounties}\n",
        "        group by `County`\n",
        "    \"\"\").withColumn(\"Year\", lit(year))\n",
        "    \n",
        "    val columns = Seq(\"Year\") ++ countydf.columns.slice(0, 11)\n",
        "    var countydfNew = countydf.select(columns.map(countydf.col): _*)\n",
        "\n",
        "    totalNYCCountyDF = if (totalNYCCountyDF.isEmpty) countydfNew else totalNYCCountyDF.union(countydfNew)\n",
        "}\n",
        "\n",
        "z.show(totalNYCCountyDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "val avgSafetyIssueColumns = totalNYCCountyDF.columns.filter(col => col != \"Year\" && col != \"County\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "totalNYCCountyDF.createOrReplaceTempView(\"totalNYCCounty\")\n",
        "\n",
        "val NYCcountyYoYDF = spark.sql(s\"\"\"\n",
        "  select\n",
        "    cur.County,\n",
        "    cur.Year,\n",
        "    ${avgSafetyIssueColumns.map{col =>\n",
        "        val name = col.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "        s\"round((cur.`$col` - prev.`$col`) / prev.`$col` * 100, 2) AS `${name}_YoY (%)`\"\n",
        "    }.mkString(\",\\n    \")}\n",
        "  from\n",
        "    totalNYCCounty cur\n",
        "  join\n",
        "    totalNYCCounty prev\n",
        "  on\n",
        "    cur.Year = prev.Year + 1\n",
        "    and cur.County = prev.County\n",
        "\"\"\")\n",
        "\n",
        "z.show(NYCcountyYoYDF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outside of NYC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "var totalOutCountyDF: DataFrame = spark.emptyDataFrame\n",
        "\n",
        "for (year <- 2018 to 2023) {\n",
        "    var countydf = spark.sql(s\"\"\"\n",
        "        select `County`, ${safetyIssueColumns.map(col => s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n",
        "        from safety$year\n",
        "        where `County` not in ${nyccounties}\n",
        "        group by `County`\n",
        "    \"\"\").withColumn(\"Year\", lit(year))\n",
        "    \n",
        "    val columns = Seq(\"Year\") ++ countydf.columns.slice(0, 11)\n",
        "    var countydfNew = countydf.select(columns.map(countydf.col): _*)\n",
        "\n",
        "    totalOutCountyDF = if (totalOutCountyDF.isEmpty) countydfNew else totalOutCountyDF.union(countydfNew)\n",
        "}\n",
        "\n",
        "z.show(totalOutCountyDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "totalOutCountyDF.createOrReplaceTempView(\"totalOutCounty\")\n",
        "\n",
        "val outCountyYoYDF = spark.sql(s\"\"\"\n",
        "  select\n",
        "    cur.County,\n",
        "    cur.Year,\n",
        "    ${avgSafetyIssueColumns.map{col =>\n",
        "        val name = col.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "        s\"round((cur.`$col` - prev.`$col`) / prev.`$col` * 100, 2) AS `${name}_YoY (%)`\"\n",
        "    }.mkString(\",\\n    \")}\n",
        "  from\n",
        "    totalOutCounty cur\n",
        "  join\n",
        "    totalOutCounty prev\n",
        "  on\n",
        "    cur.Year = prev.Year + 1\n",
        "    and cur.County = prev.County\n",
        "\"\"\")\n",
        "\n",
        "z.show(outCountyYoYDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Per School"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "// concat all the cleaned datasets views from 2018 to 2023 into one\n",
        "val allDF = spark.sql(\"\"\"\n",
        "  select * , 2018 as Year from safety2018\n",
        "  union all\n",
        "  select * , 2019 as Year from safety2019\n",
        "  union all\n",
        "  select * , 2020 as Year from safety2020\n",
        "  union all\n",
        "  select * , 2021 as Year from safety2021\n",
        "  union all\n",
        "  select * , 2022 as Year from safety2022\n",
        "  union all\n",
        "  select * , 2023 as Year from safety2023\n",
        "\"\"\")\n",
        "\n",
        "allDF.createOrReplaceTempView(\"all\")\n",
        "\n",
        "z.show(allDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In NYC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "val NYCschoolDF = spark.sql(s\"\"\"\n",
        "    select BEDS_Code, County, ${safetyIssueColumns.map(col => s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n",
        "    from all\n",
        "    where County in ${nyccounties}\n",
        "    group by BEDS_Code, County\n",
        "\"\"\").withColumn(\"Sum_Avg_Safety_Issues\", avgSafetyIssueColumns.map(col).reduce(_ + _))\n",
        "\n",
        "z.show(NYCschoolDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "NYCschoolDF.createOrReplaceTempView(\"NYCschool\")\n",
        "\n",
        "val topSchoolDF = spark.sql(\"\"\"\n",
        "    select *\n",
        "    from NYCschool\n",
        "    order by Sum_Avg_Safety_Issues desc\n",
        "    limit 10\n",
        "\"\"\")\n",
        "\n",
        "z.show(topSchoolDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outside of NYC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "val outSchoolDF = spark.sql(s\"\"\"\n",
        "    select BEDS_Code, County, ${safetyIssueColumns.map(col => s\"avg(`$col`) as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n",
        "    from all\n",
        "    where County not in ${nyccounties}\n",
        "    group by BEDS_Code, County\n",
        "\"\"\").withColumn(\"Sum_Avg_Safety_Issues\", avgSafetyIssueColumns.map(col).reduce(_ + _))\n",
        "\n",
        "z.show(outSchoolDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "outSchoolDF.createOrReplaceTempView(\"outSchool\")\n",
        "\n",
        "val topOutSchoolDF = spark.sql(\"\"\"\n",
        "    select *\n",
        "    from outSchool\n",
        "    order by Sum_Avg_Safety_Issues desc\n",
        "    limit 10\n",
        "\"\"\")\n",
        "\n",
        "z.show(topOutSchoolDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Per Safety Issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In NYC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "var avgNYCSafetyIssueDF: DataFrame = spark.emptyDataFrame\n",
        "\n",
        "for (year <- 2018 to 2023) {\n",
        "    \n",
        "    val count = safetydf.count()\n",
        "    // sum the number of each violations / number of schools\n",
        "    var avg = spark.sql(s\"\"\"\n",
        "        select ${safetyIssueColumns.map(col => s\"sum(`$col`)/$count as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n",
        "        from safety${year}\n",
        "        where County in $nyccounties\n",
        "    \"\"\").withColumn(\"Year\", lit(year))\n",
        "    \n",
        "    val columns = Seq(\"Year\") ++ avg.columns.slice(0, 11)\n",
        "    var avgNew = avg.select(columns.map(avg.col): _*)\n",
        "    \n",
        "    avgNYCSafetyIssueDF = if (avgNYCSafetyIssueDF.isEmpty) avgNew else avgNYCSafetyIssueDF.union(avgNew)\n",
        "}\n",
        "\n",
        "z.show(avgNYCSafetyIssueDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "avgNYCSafetyIssueDF.createOrReplaceTempView(\"avg_nyc_safety_issues\")\n",
        "\n",
        "val maxNYCSafetyIssuesDF = spark.sql(s\"\"\"\n",
        "    select *,\n",
        "            case\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Homocide` then 'Avg_Homocide'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Sexual_Offense` then 'Avg_Sexual_Offense'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Assault` then 'Avg_Assault'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Weapons_Possession` then 'Avg_Weapons_Possession'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Dignity_Act_Excluding_Cyberbullying` then 'Avg_Dignity_Act_Excluding_Cyberbullying'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Dignity_Act_Cyberbullying` then 'Avg_Dignity_Act_Cyberbullying'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Bomb_Threat` then 'Avg_Bomb_Threat'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_False_Alarm` then 'Avg_False_Alarm'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Drugs` then 'Avg_Drugs'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Alcohol` then 'Avg_Alcohol'\n",
        "                else 'Unknown'\n",
        "            end as Max_Safety_Issue\n",
        "    from avg_nyc_safety_issues\n",
        "\"\"\")\n",
        "\n",
        "z.show(maxNYCSafetyIssuesDF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outside of NYC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "var avgOutSafetyIssueDF: DataFrame = spark.emptyDataFrame\n",
        "\n",
        "for (year <- 2018 to 2023) {\n",
        "    \n",
        "    val count = safetydf.count()\n",
        "    // sum the number of each violations / number of schools\n",
        "    var avg = spark.sql(s\"\"\"\n",
        "        select ${safetyIssueColumns.map(col => s\"sum(`$col`)/$count as Avg_${col.replace(\" \", \"_\").replace(\"-\", \"_\")}\").mkString(\", \")}\n",
        "        from safety${year}\n",
        "        where County not in $nyccounties\n",
        "    \"\"\").withColumn(\"Year\", lit(year))\n",
        "    \n",
        "    val columns = Seq(\"Year\") ++ avg.columns.slice(0, 11)\n",
        "    var avgNew = avg.select(columns.map(avg.col): _*)\n",
        "    \n",
        "    avgOutSafetyIssueDF = if (avgOutSafetyIssueDF.isEmpty) avgNew else avgOutSafetyIssueDF.union(avgNew)\n",
        "}\n",
        "\n",
        "z.show(avgOutSafetyIssueDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "avgOutSafetyIssueDF.createOrReplaceTempView(\"avg_out_safety_issues\")\n",
        "\n",
        "val maxOutSafetyIssuesDF = spark.sql(s\"\"\"\n",
        "    select *,\n",
        "            case\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Homocide` then 'Avg_Homocide'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Sexual_Offense` then 'Avg_Sexual_Offense'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Assault` then 'Avg_Assault'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Weapons_Possession` then 'Avg_Weapons_Possession'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Dignity_Act_Excluding_Cyberbullying` then 'Avg_Dignity_Act_Excluding_Cyberbullying'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Dignity_Act_Cyberbullying` then 'Avg_Dignity_Act_Cyberbullying'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Bomb_Threat` then 'Avg_Bomb_Threat'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_False_Alarm` then 'Avg_False_Alarm'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Drugs` then 'Avg_Drugs'\n",
        "                when greatest(${avgSafetyIssueColumns.map(col => s\"`${col}`\").mkString(\", \")}) = `Avg_Alcohol` then 'Avg_Alcohol'\n",
        "                else 'Unknown'\n",
        "            end as Max_Safety_Issue\n",
        "    from avg_out_safety_issues\n",
        "\"\"\")\n",
        "\n",
        "z.show(maxOutSafetyIssuesDF)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "safety_analysis.ipynb"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
